{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skin-cancer-mnist-ham10000']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraties\n",
    "import os, cv2,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/skin-cancer-mnist-ham10000'\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10015/10015 [01:43<00:00, 96.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3, 10015)\n",
      "normMean = [0.763038, 0.54564667, 0.57004464]\n",
      "normStd = [0.14092727, 0.15261286, 0.1699712]\n"
     ]
    }
   ],
   "source": [
    "norm_mean,norm_std = compute_img_mean_std(all_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "1  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "2  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "3  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "4  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "\n",
       "                        cell_type  cell_type_idx  \n",
       "0  Benign keratosis-like lesions               2  \n",
       "1  Benign keratosis-like lesions               2  \n",
       "2  Benign keratosis-like lesions               2  \n",
       "3  Benign keratosis-like lesions               2  \n",
       "4  Benign keratosis-like lesions               2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "df_original.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  path  \\\n",
       "0  HAM_0000001         1   1        1    1    1             1     1   \n",
       "1  HAM_0000003         1   1        1    1    1             1     1   \n",
       "2  HAM_0000004         1   1        1    1    1             1     1   \n",
       "3  HAM_0000007         1   1        1    1    1             1     1   \n",
       "4  HAM_0000008         1   1        1    1    1             1     1   \n",
       "\n",
       "   cell_type  cell_type_idx  \n",
       "0          1              1  \n",
       "1          1              1  \n",
       "2          1              1  \n",
       "3          1              1  \n",
       "4          1              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df_undup = df_original.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>HAM_0003602</td>\n",
       "      <td>ISIC_0033004</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>female</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>dermatofibroma</td>\n",
       "      <td>6</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>HAM_0000137</td>\n",
       "      <td>ISIC_0027460</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>HAM_0007343</td>\n",
       "      <td>ISIC_0033831</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>dermatofibroma</td>\n",
       "      <td>6</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>HAM_0000176</td>\n",
       "      <td>ISIC_0033696</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>dermatofibroma</td>\n",
       "      <td>6</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>HAM_0002369</td>\n",
       "      <td>ISIC_0027016</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input/skin-cancer-mnist-ham10000/ham10000_i...</td>\n",
       "      <td>Melanocytic nevi</td>\n",
       "      <td>4</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id   dx    dx_type   age     sex  \\\n",
       "1629  HAM_0003602  ISIC_0033004  mel      histo  30.0  female   \n",
       "4702  HAM_0000137  ISIC_0027460   nv  follow_up  50.0    male   \n",
       "1514  HAM_0007343  ISIC_0033831  mel      histo  70.0    male   \n",
       "1865  HAM_0000176  ISIC_0033696  mel      histo  65.0    male   \n",
       "4375  HAM_0002369  ISIC_0027016   nv  follow_up  40.0  female   \n",
       "\n",
       "         localization                                               path  \\\n",
       "1629  upper extremity  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "4702  upper extremity  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "1514            chest  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "1865  upper extremity  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "4375              ear  ../input/skin-cancer-mnist-ham10000/ham10000_i...   \n",
       "\n",
       "             cell_type  cell_type_idx    duplicates  \n",
       "1629    dermatofibroma              6    duplicated  \n",
       "4702  Melanocytic nevi              4  unduplicated  \n",
       "1514    dermatofibroma              6    duplicated  \n",
       "1865    dermatofibroma              6    duplicated  \n",
       "4375  Melanocytic nevi              4  unduplicated  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only one image.\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_original['duplicates'] = df_original['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n",
    "df_original.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unduplicated    5514\n",
       "duplicated      4501\n",
       "Name: duplicates, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we create a val set using df because we are sure that none of these images have augmented duplicates in the train set\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    883\n",
       "2     88\n",
       "6     46\n",
       "1     35\n",
       "0     30\n",
       "5     13\n",
       "3      8\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8912\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "# This set will be df_original excluding all rows that are in the val set\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_original['train_or_val'] = df_original['image_id']\n",
    "# apply the function to this new column\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df_train = df_original[df_original['train_or_val'] == 'train']\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5822\n",
       "6    1067\n",
       "2    1011\n",
       "1     479\n",
       "0     297\n",
       "5     129\n",
       "3     107\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  883\n",
       "Benign keratosis-like lesions      88\n",
       "dermatofibroma                     46\n",
       "Basal cell carcinoma               35\n",
       "Actinic keratoses                  30\n",
       "Vascular lesions                   13\n",
       "Dermatofibroma                      8\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  5822\n",
       "Dermatofibroma                    5350\n",
       "dermatofibroma                    5335\n",
       "Vascular lesions                  5160\n",
       "Benign keratosis-like lesions     5055\n",
       "Basal cell carcinoma              4790\n",
       "Actinic keratoses                 4455\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy fewer class to balance the number of 7 classes\n",
    "data_aug_rate = [15,10,5,50,0,40,5]\n",
    "for i in range(7):\n",
    "    if data_aug_rate[i]:\n",
    "        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n",
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val, df_test = train_test_split(df_val, test_size=0.5)\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()\n",
    "# df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    \"\"\" VGG19_bn \"\"\"\n",
    "    model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    input_size = 224\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /tmp/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth\n",
      "100%|██████████| 548M/548M [00:08<00:00, 67.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "num_classes = 7\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "# Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "# norm_std = (0.24703233, 0.24348505, 0.26158768)\n",
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for this dataset\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Adam optimizer, use cross entropy loss as our loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 1124], [train loss 1.80398], [train acc 0.26000]\n",
      "[epoch 1], [iter 200 / 1124], [train loss 1.74280], [train acc 0.28094]\n",
      "[epoch 1], [iter 300 / 1124], [train loss 1.69131], [train acc 0.30042]\n",
      "[epoch 1], [iter 400 / 1124], [train loss 1.65107], [train acc 0.31422]\n",
      "[epoch 1], [iter 500 / 1124], [train loss 1.61708], [train acc 0.32588]\n",
      "[epoch 1], [iter 600 / 1124], [train loss 1.59189], [train acc 0.33932]\n",
      "[epoch 1], [iter 700 / 1124], [train loss 1.57105], [train acc 0.34750]\n",
      "[epoch 1], [iter 800 / 1124], [train loss 1.54800], [train acc 0.35801]\n",
      "[epoch 1], [iter 900 / 1124], [train loss 1.53269], [train acc 0.36861]\n",
      "[epoch 1], [iter 1000 / 1124], [train loss 1.51890], [train acc 0.37719]\n",
      "[epoch 1], [iter 1100 / 1124], [train loss 1.49893], [train acc 0.38778]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.83742], [val acc 0.71994]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 0.83742], [val acc 0.71994]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 1124], [train loss 1.28054], [train acc 0.51187]\n",
      "[epoch 2], [iter 200 / 1124], [train loss 1.26343], [train acc 0.51234]\n",
      "[epoch 2], [iter 300 / 1124], [train loss 1.24922], [train acc 0.51917]\n",
      "[epoch 2], [iter 400 / 1124], [train loss 1.24473], [train acc 0.52258]\n",
      "[epoch 2], [iter 500 / 1124], [train loss 1.23700], [train acc 0.52706]\n",
      "[epoch 2], [iter 600 / 1124], [train loss 1.23072], [train acc 0.52870]\n",
      "[epoch 2], [iter 700 / 1124], [train loss 1.22339], [train acc 0.53022]\n",
      "[epoch 2], [iter 800 / 1124], [train loss 1.21957], [train acc 0.53273]\n",
      "[epoch 2], [iter 900 / 1124], [train loss 1.21070], [train acc 0.53649]\n",
      "[epoch 2], [iter 1000 / 1124], [train loss 1.20269], [train acc 0.53969]\n",
      "[epoch 2], [iter 1100 / 1124], [train loss 1.19324], [train acc 0.54477]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.86824], [val acc 0.69226]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 1124], [train loss 1.10837], [train acc 0.58875]\n",
      "[epoch 3], [iter 200 / 1124], [train loss 1.11461], [train acc 0.58875]\n",
      "[epoch 3], [iter 300 / 1124], [train loss 1.14911], [train acc 0.58500]\n",
      "[epoch 3], [iter 400 / 1124], [train loss 1.15293], [train acc 0.58469]\n",
      "[epoch 3], [iter 500 / 1124], [train loss 1.20898], [train acc 0.57075]\n",
      "[epoch 3], [iter 600 / 1124], [train loss 1.31659], [train acc 0.55125]\n",
      "[epoch 3], [iter 700 / 1124], [train loss 1.35882], [train acc 0.53701]\n",
      "[epoch 3], [iter 800 / 1124], [train loss 1.35225], [train acc 0.53723]\n",
      "[epoch 3], [iter 900 / 1124], [train loss 1.32879], [train acc 0.54212]\n",
      "[epoch 3], [iter 1000 / 1124], [train loss 1.30571], [train acc 0.54709]\n",
      "[epoch 3], [iter 1100 / 1124], [train loss 1.28244], [train acc 0.55156]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.60529], [val acc 0.76214]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 3], [val loss 0.60529], [val acc 0.76214]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 / 1124], [train loss 1.07492], [train acc 0.59875]\n",
      "[epoch 4], [iter 200 / 1124], [train loss 1.05789], [train acc 0.60953]\n",
      "[epoch 4], [iter 300 / 1124], [train loss 1.09047], [train acc 0.60385]\n",
      "[epoch 4], [iter 400 / 1124], [train loss 1.13011], [train acc 0.59461]\n",
      "[epoch 4], [iter 500 / 1124], [train loss 1.14670], [train acc 0.59206]\n",
      "[epoch 4], [iter 600 / 1124], [train loss 1.13240], [train acc 0.59594]\n",
      "[epoch 4], [iter 700 / 1124], [train loss 1.11756], [train acc 0.59946]\n",
      "[epoch 4], [iter 800 / 1124], [train loss 1.10899], [train acc 0.60066]\n",
      "[epoch 4], [iter 900 / 1124], [train loss 1.09985], [train acc 0.60351]\n",
      "[epoch 4], [iter 1000 / 1124], [train loss 1.08530], [train acc 0.60725]\n",
      "[epoch 4], [iter 1100 / 1124], [train loss 1.06940], [train acc 0.61128]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.82002], [val acc 0.69673]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 1124], [train loss 0.92495], [train acc 0.65406]\n",
      "[epoch 5], [iter 200 / 1124], [train loss 0.94358], [train acc 0.64953]\n",
      "[epoch 5], [iter 300 / 1124], [train loss 0.93924], [train acc 0.65490]\n",
      "[epoch 5], [iter 400 / 1124], [train loss 0.91462], [train acc 0.65914]\n",
      "[epoch 5], [iter 500 / 1124], [train loss 0.90469], [train acc 0.65919]\n",
      "[epoch 5], [iter 600 / 1124], [train loss 0.90743], [train acc 0.65677]\n",
      "[epoch 5], [iter 700 / 1124], [train loss 0.90565], [train acc 0.65790]\n",
      "[epoch 5], [iter 800 / 1124], [train loss 0.89919], [train acc 0.66039]\n",
      "[epoch 5], [iter 900 / 1124], [train loss 0.89468], [train acc 0.66222]\n",
      "[epoch 5], [iter 1000 / 1124], [train loss 0.89563], [train acc 0.66219]\n",
      "[epoch 5], [iter 1100 / 1124], [train loss 0.89235], [train acc 0.66324]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.51834], [val acc 0.81673]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 5], [val loss 0.51834], [val acc 0.81673]\n",
      "*****************************************************\n",
      "[epoch 6], [iter 100 / 1124], [train loss 0.81989], [train acc 0.68875]\n",
      "[epoch 6], [iter 200 / 1124], [train loss 0.82003], [train acc 0.69016]\n",
      "[epoch 6], [iter 300 / 1124], [train loss 0.81490], [train acc 0.68792]\n",
      "[epoch 6], [iter 400 / 1124], [train loss 0.81388], [train acc 0.68758]\n",
      "[epoch 6], [iter 500 / 1124], [train loss 0.81700], [train acc 0.68619]\n",
      "[epoch 6], [iter 600 / 1124], [train loss 0.81513], [train acc 0.68688]\n",
      "[epoch 6], [iter 700 / 1124], [train loss 0.82170], [train acc 0.68312]\n",
      "[epoch 6], [iter 800 / 1124], [train loss 0.82385], [train acc 0.68312]\n",
      "[epoch 6], [iter 900 / 1124], [train loss 0.82077], [train acc 0.68521]\n",
      "[epoch 6], [iter 1000 / 1124], [train loss 0.81920], [train acc 0.68641]\n",
      "[epoch 6], [iter 1100 / 1124], [train loss 0.81500], [train acc 0.68812]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 0.55794], [val acc 0.77643]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [iter 100 / 1124], [train loss 0.78377], [train acc 0.70469]\n",
      "[epoch 7], [iter 200 / 1124], [train loss 0.78701], [train acc 0.70531]\n",
      "[epoch 7], [iter 300 / 1124], [train loss 0.79156], [train acc 0.70365]\n",
      "[epoch 7], [iter 400 / 1124], [train loss 0.78018], [train acc 0.70555]\n",
      "[epoch 7], [iter 500 / 1124], [train loss 0.77849], [train acc 0.70550]\n",
      "[epoch 7], [iter 600 / 1124], [train loss 0.77047], [train acc 0.70750]\n",
      "[epoch 7], [iter 700 / 1124], [train loss 0.76566], [train acc 0.71076]\n",
      "[epoch 7], [iter 800 / 1124], [train loss 0.76185], [train acc 0.71230]\n",
      "[epoch 7], [iter 900 / 1124], [train loss 0.76072], [train acc 0.71094]\n",
      "[epoch 7], [iter 1000 / 1124], [train loss 0.75828], [train acc 0.71088]\n",
      "[epoch 7], [iter 1100 / 1124], [train loss 0.75498], [train acc 0.71193]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 0.55879], [val acc 0.78714]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [iter 100 / 1124], [train loss 0.70391], [train acc 0.72469]\n",
      "[epoch 8], [iter 200 / 1124], [train loss 0.71438], [train acc 0.72625]\n",
      "[epoch 8], [iter 300 / 1124], [train loss 0.71726], [train acc 0.72406]\n",
      "[epoch 8], [iter 400 / 1124], [train loss 0.71235], [train acc 0.72695]\n",
      "[epoch 8], [iter 500 / 1124], [train loss 0.71180], [train acc 0.72669]\n",
      "[epoch 8], [iter 600 / 1124], [train loss 0.70832], [train acc 0.72885]\n",
      "[epoch 8], [iter 700 / 1124], [train loss 0.70930], [train acc 0.72929]\n",
      "[epoch 8], [iter 800 / 1124], [train loss 0.70990], [train acc 0.72934]\n",
      "[epoch 8], [iter 900 / 1124], [train loss 0.71043], [train acc 0.72913]\n",
      "[epoch 8], [iter 1000 / 1124], [train loss 0.70945], [train acc 0.72975]\n",
      "[epoch 8], [iter 1100 / 1124], [train loss 0.70872], [train acc 0.73037]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 0.47532], [val acc 0.82185]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 8], [val loss 0.47532], [val acc 0.82185]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9], [iter 100 / 1124], [train loss 0.68674], [train acc 0.74156]\n",
      "[epoch 9], [iter 200 / 1124], [train loss 0.66817], [train acc 0.74484]\n",
      "[epoch 9], [iter 300 / 1124], [train loss 0.68369], [train acc 0.73740]\n",
      "[epoch 9], [iter 400 / 1124], [train loss 0.68073], [train acc 0.73664]\n",
      "[epoch 9], [iter 500 / 1124], [train loss 0.67861], [train acc 0.73931]\n",
      "[epoch 9], [iter 600 / 1124], [train loss 0.68043], [train acc 0.74115]\n",
      "[epoch 9], [iter 700 / 1124], [train loss 0.67311], [train acc 0.74326]\n",
      "[epoch 9], [iter 800 / 1124], [train loss 0.66680], [train acc 0.74602]\n",
      "[epoch 9], [iter 900 / 1124], [train loss 0.66797], [train acc 0.74538]\n",
      "[epoch 9], [iter 1000 / 1124], [train loss 0.66488], [train acc 0.74506]\n",
      "[epoch 9], [iter 1100 / 1124], [train loss 0.66190], [train acc 0.74651]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 0.47327], [val acc 0.82554]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 9], [val loss 0.47327], [val acc 0.82554]\n",
      "*****************************************************\n",
      "[epoch 10], [iter 100 / 1124], [train loss 0.60971], [train acc 0.76406]\n",
      "[epoch 10], [iter 200 / 1124], [train loss 0.62274], [train acc 0.76187]\n",
      "[epoch 10], [iter 300 / 1124], [train loss 0.63137], [train acc 0.75844]\n",
      "[epoch 10], [iter 400 / 1124], [train loss 0.61906], [train acc 0.76469]\n",
      "[epoch 10], [iter 500 / 1124], [train loss 0.62037], [train acc 0.76394]\n",
      "[epoch 10], [iter 600 / 1124], [train loss 0.62576], [train acc 0.76120]\n",
      "[epoch 10], [iter 700 / 1124], [train loss 0.63103], [train acc 0.75960]\n",
      "[epoch 10], [iter 800 / 1124], [train loss 0.62781], [train acc 0.76035]\n",
      "[epoch 10], [iter 900 / 1124], [train loss 0.62344], [train acc 0.76205]\n",
      "[epoch 10], [iter 1000 / 1124], [train loss 0.62827], [train acc 0.76006]\n",
      "[epoch 10], [iter 1100 / 1124], [train loss 0.62560], [train acc 0.76122]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 0.51454], [val acc 0.82274]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
